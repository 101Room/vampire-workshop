# Некоторые сведения про параллельность

### Нужна ли она вообще вам? Можно ли запустить на одном, но многоядерном процессоре параллельно что-то или нужно именно несколько процессоров или кластер из нескольких машин?

MPI является стандартом для крупномасштабных научных вычислений и уже широко используется на многоядерных машинах. Прямо сейчас, ничто не масштабируется больше, чем MPI. Использовать или хотя бы рассмотреть возможность использования MPI стоит, если вы ожидаете того, что ваш код будет масштабироваться на большее число машин/процессоров. Вы можете работать с MPI на обычном многоядерном процессоре, при этом миграция в кластер будет довольно безболезненной. Перед погружением стоит помнить, что MPI был разработан для решения крупномасштабных научных задач в системах с распределенной памятью. Многоядерные блоки, с которыми вы, возможно, имеете дело, вероятно, имеют общую память. Предостережение заключается в том, что MPI – не самая простая вещь, которую вы можете использовать для получения параллелизма на одном многоядерном процессоре. В MPI вся передача сообщений является явной. По этой причине он был назван "ассемблером" параллельного программирования. Наконец, если вы пишете приложение, которое всегда будет нуждаться только в одной машине, то можно попробовать что-нибудь другое, например перестать думать о параллельности вовсе. Хотя на самом деле с ней расчёты идут быстрее (у меня вот точно идут быстрее, вы у себя можете посмотреть по времени выполнения моделирования быстрее или нет), так что профит о ней думать есть некоторый.

##### Если вы не очень знакомы с основами ОС, не понимаете что такое параллельность и CUDA, если вам интересно как вообще происходит параллелизация и возможно ли что-то параллельить на одном процессоре, то читайте далее

Тут я простым языком объясню суть всего этого. Если вам это не сдалось, то просто пропустите. В этом отрывке все процессоры считаются одноядерными, для простоты повествования.

#### Параллельность как иллюзия.

Все, что происходит в компьютере состоит из процессов. Любое взаимодействие с устройством требует создания процесса, любое выполнение чего-то в программе тоже. ОС имеет в себе средства и какую-то логику, по которой происходит раздача приоритетов процессам, переключение между ними. Вам лишь кажется, что компьютер одновременно играет музыку, двигает курсором на экране, и что у него ещё работает 7 программ на фоне. Он делает в один момент только что-то одно, просто он переключается настолько быстро, что вы и не успеваете заметить. Есть медленные устройства, от которых очень долго по меркам процессора ожидается отклик (жёсткие диски, которые вращаются). И тут у ОС должны быть «мозги» на то, чтобы временно оставить этот диск, выполнить других процессов, и после, когда он прокрутится, вернуться к нему. В разных ОС может быть разная реализация того, как оптимизировать всё это и организовать. ОС может существенно ускорить и оптимизировать вашу работу за компьютером посредством грамотных переключений и расстановок приоритетов. Но это не настоящая параллельность, а псевдопараллельность (называется многозадачность). Оптимизация может быть достигнута и с помощью установки некоторых библиотек.
Реальная параллельность происходит тогда, когда несколько процессоров или компьютеров делят задачи. Для оптимизации процесса разделения может быть использована библиотека. MPI и MPICH, которая появилась из неё, как раз являются примерами таких библиотек. Так что не важно один у вас процессор или несколько, библиотеки будут вам союзником.
Что касается прочих фокусов, когда вычисления пытаются переложить на графические процессоры (они в нынешних видеокартах часто используются для расчётов трёхмерной графики, их используют для майнинга биткойнов и прочих криптовалют в силу специфики вычислений), то это работает, если, грубо говоря, у вас одна формула и миллион аргументов, которые надо пропустить через эту формулу. Там как бы множество подпроцессоров, но они могут выполнять только однотипные задачи, но да, с большим числом объектов. CUDA это программно-аппаратная архитектура от NVIDIA, рассчитанная на увеличение производительности таким путём.

#### Воспроизводимость как иллюзия.

Детерминированность результатов программы может исчезнуть, если она зависит от порядка выполнения каких-то процессов. В один запуск будет один порядок, а при другом запуске может изменится порядок выполнения (потому что контекст изменился и логика выбора приоритетов сработала иначе, например). Подобного рода вещи имеют говорящее название гейзенбаги. Говорит это о том, что нет определённости в том, возникнет ли баг на этот раз: можно наткнуться, а можно и не наткнуться, при том вероятность наткнуться может быть ничтожно малой. Но при этом быть. Однажды ошибка такого рода под названием «состояние гонки» (race condition) в ПО для магнетрона вызвала гибель двоих людей (cлучай с Therac-25), почитать об этом можно в [Википедии](https://ru.wikipedia.org/wiki/Состояние_гонки). Посему, запускать одну и ту же программу, каждый раз надеясь на другой результат, не такое уж и безумие.

#### Складность как иллюзия.

Многозадачность может породить такие состояния как дедлок (deadlock) и лайвлок (livelock). Между ними есть некоторое отличие, но суть одна и та же: первый процесс ждёт чего-то от второго (например, чтобы даны освободил, которые ему нужны), а второй не может ничего сделать, потому что ждёт от первого тоже чего-то, но первый не работает потому что он ждёт чего-то от второго… Как два барана, которые застряли на мосту. Можно позаботиться о предотвращении таких ситуаций при написании кода программы.